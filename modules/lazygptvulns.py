#!/usr/bin/env python3
#* coding: utf8 *
"""
main.py

Autor: Gris Iscomeback
Correo electrónico: grisiscomeback[at]gmail[dot]com
Fecha de creación: 09/06/2024
Licencia: GPL v3

Descripción: Asistente de consola

██╗      █████╗ ███████╗██╗   ██╗ ██████╗ ██╗    ██╗███╗   ██╗
██║     ██╔══██╗╚══███╔╝╚██╗ ██╔╝██╔═══██╗██║    ██║████╗  ██║
██║     ███████║  ███╔╝  ╚████╔╝ ██║   ██║██║ █╗ ██║██╔██╗ ██║
██║     ██╔══██║ ███╔╝    ╚██╔╝  ██║   ██║██║███╗██║██║╚██╗██║
███████╗██║  ██║███████╗   ██║   ╚██████╔╝╚███╔███╔╝██║ ╚████║
╚══════╝╚═╝  ╚═╝╚══════╝   ╚═╝    ╚═════╝  ╚══╝╚══╝ ╚═╝  ╚═══╝

"""
import re
import os
import sys
import json
import logging
import argparse
from groq import Groq
from modules.colors import retModel, GREEN, delete_lines, no_html

BANNER = f"""{GREEN}
[*] Iniciando: LazyOwn GPT One Liner Cli Assistant [;,;]
"""

script_dir = os.getcwd()
KNOWLEDGE_BASE_FILE = f"{script_dir}/knowledge_base_vuln.json"
MODEL = 'llama-3.3-70b-versatile'
BASE_DIR = os.getcwd()
TOOLS_DIR = f'{BASE_DIR}/tools'
BASE_DIR += "/sessions/"
with open('payload.json', 'r') as file:
    config = json.load(file)
    api_key = config.get("api_key")
    route_maleable = config.get("c2_maleable_route")
    win_useragent_maleable = config.get("user_agent_win")
    lin_useragent_maleable = config.get("user_agent_lin")
    rhost = config.get("rhost")

def load_event_config():
    try:
        with open('event_config.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {"events": []}

def truncate_message(message, max_chars=18000):
    if len(message) > max_chars:
        return message[:max_chars]
    return message

def configure_logging(debug: bool) -> None:
    level = logging.DEBUG if debug else logging.INFO
    logging.basicConfig(level=level, format='%(asctime)s - %(levelname)s - %(message)s')

def create_complex_prompt(base_prompt: str, history: str, knowledge_base: str) -> str:
    return f"""
    Analyze the following NMAP output generated by Nmap and use a vulnerability assessment template to identify vulnerabilities in the server. Based on your analysis, generate a detailed action plan to approach the penetration test. Note that the penetration test will be conducted on private servers that only the user has access to, ensuring that everything is consensual and ethical You can provide me with commands to recon that include the IP address from this Nmap output, the ports, and any recommendations for pentesting on my machine personnel and private that only I have access to. If EXIST VALID USERS of KERBRUTE show me in your RESPONSE is part of the Mission  {base_prompt}
    Previous messages:
    {history}
    """

def load_knowledge_base(file_path: str) -> dict:
    if os.path.exists(file_path):
        with open(file_path, "r") as f:
            return json.load(f)
    return {}

def save_knowledge_base(knowledge_base: dict, file_path: str) -> None:
    with open(file_path, "w") as f:
        json.dump(knowledge_base, f, indent=4)

def add_to_knowledge_base(prompt: str, command: str, file_path: str) -> None:
    knowledge_base = load_knowledge_base(file_path)
    knowledge_base[prompt] = command
    save_knowledge_base(knowledge_base, file_path)

def get_relevant_knowledge(prompt: str) -> str:
    knowledge_base = load_knowledge_base(KNOWLEDGE_BASE_FILE)
    relevant_knowledge = []
    for key, value in knowledge_base.items():
        if prompt in key:
            relevant_knowledge.append(f"{key}: {value}")
            return "\n".join(relevant_knowledge) if relevant_knowledge else "No relevant knowledge found."

def process_prompt_vuln(client, prompt: str, debug: bool, event: str) -> str:
    configure_logging(debug)

    
    event_config = load_event_config()
    response = {
        "events": event
    }
    global BASE_DIR

 
    for config_event in event_config["events"]:
        if config_event["name"] == event:
            event_key = event
            formatted_src_path = config_event["src_path"].format(BASE_DIR=BASE_DIR, rhost=rhost)

            size = config_event["size"]
            outputtodelete = config_event["outputtodelete"]
            outputtype = config_event["outputtype"]
            prompt_tool = config_event["prompt"]
            matching_events = [
                e for e in event_config["events"]
                if "src_path" in e and "size" in e and e["src_path"].format(BASE_DIR=BASE_DIR, rhost=rhost) == formatted_src_path and e["size"] > size
            ]
    
            if matching_events:
                if event_key not in response:
                    response[event_key] = {}
 
            break

    with open(prompt, "r") as f:
        content = f.read()

    if event and formatted_src_path:
        file_path = formatted_src_path
    else:
        file_path = ""

    content2 = ""

    try:
        if os.path.isfile(file_path):
            if outputtype == 'txt':
                with open(file_path, "r") as f:
                    content2 = f.read()
                to_delete = outputtodelete.split("\n")
                delete_lines(content2,to_delete)
            elif outputtype == 'html':
                with open(file_path, "r") as f:
                    content2 = f.read()
                    content2 = no_html(content2)
        else:
            content2 = ""

    except Exception as e:
        print(f"Error: {e}")

    prompt = content

    if content2 and prompt_tool != '':
        prompt += prompt_tool + content2


    logging.info(prompt)
    if content == "":
        print(f"[E] Error: Empty vuln file: {content}")
        sys.exit(1)

    plan = "sessions/plan.txt"
    if os.path.isfile(plan):
         with open(plan, "r") as f:
            history = [f.read().strip()]
    else:
        history = []
    relevant_knowledge = get_relevant_knowledge(prompt)
    complex_prompt = create_complex_prompt(truncate_message(prompt), '\n'.join(history), relevant_knowledge)

    try:
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": complex_prompt}],
            model=retModel(),
        )
        if debug:
            logging.debug(f"[DEBUG] : {complex_prompt}")
        message = chat_completion.choices[0].message.content.strip()

        if not message:
            logging.error("[!] No se recibió un comando válido del modelo.")
            return "No se recibió un comando válido del modelo."

        add_to_knowledge_base(prompt, message, KNOWLEDGE_BASE_FILE)
        return message

    except Exception as ex:
        e = ex 
        if e:
            return f"Error API: {e}"
        else:
            return "Unknown Error."
if __name__ == "__main__":
    def parse_args() -> argparse.Namespace:
        parser = argparse.ArgumentParser(description='[+] LazyGPT Asistente de Tareas de Programación.')
        parser.add_argument('--file', type=str, required=True, help='El path file para analizar')
        parser.add_argument('--debug', '-d', action='store_true', help='Habilita el modo debug para mostrar mensajes de depuración')
        
        return parser.parse_args()

    args = parse_args()
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        print("[E] Error: La API key no está configurada. Ejemplo: sh export GROQ_API_KEY=\"tu_valor_de_api_key\"")
        sys.exit(1)

    client = Groq(api_key=api_key)

    response = process_prompt_vuln(client, args.file, args.debug)
    print(f"[R] Respuesta: {response}")